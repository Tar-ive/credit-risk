# -*- coding: utf-8 -*-
"""Untitled86.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16uXku6TvMLJCw0HwVk7bGQ8h_q_lOK1V
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

train = pd.read_csv('cs-training.csv').drop('Unnamed: 0', axis=1)
#test = pd.read_csv('cs-test.csv').drop('Unnamed: 0', axis=1)

train.head()

train.info()

train.describe()

train.duplicated().value_counts()

train_df = train.drop_duplicates()

train_df.duplicated().value_counts()

train_df.shape

def findMiss(df):
  return round(df.isnull().sum()/train_df.shape[0]*100,2)

findMiss(train_df)

train_df[train_df.MonthlyIncome.isnull()].describe()

train_df.NumberOfDependents.max()

train_df['NumberOfDependents'].agg(['mode'])

train_df.groupby('NumberOfDependents').size()

fam_miss = train_df[train_df.NumberOfDependents.isnull()]
fam_nmiss = train_df[train_df.NumberOfDependents.notnull()]

fam_miss.shape

fam_nmiss.shape

fam_miss['NumberOfDependents']= fam_miss['NumberOfDependents'].fillna(0)
fam_miss['MonthlyIncome']= fam_miss['MonthlyIncome'].fillna(0)

findMiss(fam_miss)

findMiss(fam_nmiss)

fam_nmiss['MonthlyIncome'].agg(['mean', 'median', 'min'])

fam_nmiss['MonthlyIncome'].agg(['max'])

fam_nmiss['MonthlyIncome'] = fam_nmiss['MonthlyIncome'].fillna(fam_nmiss['MonthlyIncome'].median())

findMiss(fam_nmiss)

train_fill = pd.concat([fam_miss, fam_nmiss])

train_fill

train_fill.shape

findMiss(train_fill)

train_fill.head()

train_fill.groupby(['SeriousDlqin2yrs']).size()/train_fill.shape[0]*100

train_fill.RevolvingUtilizationOfUnsecuredLines.describe()

train_fill.RevolvingUtilizationOfUnsecuredLines.plot(kind='box')

train_fill[train_fill['RevolvingUtilizationOfUnsecuredLines']>10].describe()

train_fill[train_fill['RevolvingUtilizationOfUnsecuredLines']>10].groupby(['SeriousDlqin2yrs']).size()

train_filled = train_fill.drop(train_fill[train_fill['RevolvingUtilizationOfUnsecuredLines']>10].index)

train_fill['MonthlyIncome'].quantile([.9])

train_filled.shape

sns.boxplot(train_filled['age'])

sns.boxplot(train_filled['NumberOfTime30-59DaysPastDueNotWorse'])

train_filled.groupby(['NumberOfTime30-59DaysPastDueNotWorse']).size()

train_filled.groupby(['NumberOfTime60-89DaysPastDueNotWorse']).size()

train_filled.groupby(['NumberOfTimes90DaysLate']).size()

train_filled[train_filled['NumberOfTimes90DaysLate']>=96].groupby(['SeriousDlqin2yrs']).size()

train_filled['DebtRatio'].describe()

sns.kdeplot(train_filled['DebtRatio'])

train_filled['DebtRatio'].quantile([.975])

train_filled[train_filled['DebtRatio']>3492][['SeriousDlqin2yrs', 'MonthlyIncome']].describe()

train_filled['MonthlyIncome'].describe()

temp = train_filled[(train_filled['DebtRatio']>3492) & (train_filled['SeriousDlqin2yrs']==train_filled['MonthlyIncome'])]

temp

temp.groupby(['SeriousDlqin2yrs']).size()

dRatio = train_filled.drop(train_filled[(train_filled['DebtRatio']>3492) & (train_filled['SeriousDlqin2yrs']==train_filled['MonthlyIncome'])].index)

dRatio.shape

dRatio.head()

dRatio.groupby(['SeriousDlqin2yrs']).size()/dRatio.shape[0]*100

train_filled.shape



from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix, classification_report
import os 

model = XGBClassifier(tree_method = 'exact')

x = dRatio.drop(['SeriousDlqin2yrs'], axis=1)
y = dRatio['SeriousDlqin2yrs']

model.fit(x, y.values.ravel())

y_pred = model.predict(x)

accuracy_score(y, y_pred)

cm = confusion_matrix(y, y_pred)

sns.heatmap(cm,annot=True,fmt='d',cmap='Oranges',linewidths=0.5,linecolor='Black')
plt.xticks(np.arange(2)+.5,['No def','def'])
plt.yticks(np.arange(2)+.5,['No def','def'])
plt.xlabel("predicted")
plt.ylabel("actuals")



print(classification_report(y,y_pred))

import pickle

# Save the model
with open('xgboost_model.pkl', 'wb') as model_file:
    pickle.dump(model, model_file)

print("Model saved successfully.")

from flask import Flask, request, jsonify
from flask_cors import CORS
import pickle
import mysql.connector
from mysql.connector import Error
import numpy as np

app = Flask(__name__)
CORS(app)

# Load the model
with open('xgboost_model.pkl', 'rb') as file:
    model = pickle.load(file)

# AWS RDS MySQL connection function
def create_db_connection():
    try:
        connection = mysql.connector.connect(
            host=os.environ.get('DB_HOST'),
            port=int(os.environ.get('DB_PORT', 3306)),
            database=os.environ.get('DB_NAME'),
            user=os.environ.get('DB_USER'),
            password=os.environ.get('DB_PASSWORD')
        )
        return connection
    except Error as e:
        print(f"Error connecting to AWS RDS MySQL database: {e}")
        return None

@app.route('/predict', methods=['POST'])
def predict():
    try:
        data = request.json
        print("Received data:", data)  # Debug print

        if not data:
            return jsonify({"error": "No data provided"}), 400

        # Extract all features from the input data
        features = [
            float(data.get('RevolvingUtilizationOfUnsecuredLines', 0)),
            float(data.get('age', 0)),
            float(data.get('NumberOfTime30-59DaysPastDueNotWorse', 0)),
            float(data.get('DebtRatio', 0)),
            float(data.get('MonthlyIncome', 0)),
            float(data.get('NumberOfOpenCreditLinesAndLoans', 0)),
            float(data.get('NumberOfTimes90DaysLate', 0)),
            float(data.get('NumberRealEstateLoansOrLines', 0)),
            float(data.get('NumberOfTime60-89DaysPastDueNotWorse', 0)),
            float(data.get('NumberOfDependents', 0))
        ]

        # Reshape for prediction
        features = np.array(features).reshape(1, -1)
        
        prediction = model.predict(features)[0]
        probability = model.predict_proba(features)[0][1]
        
        result = {
            'default_prediction': bool(prediction),
            'default_probability': float(probability)
        }
        
        # Save prediction to AWS RDS database
        connection = create_db_connection()
        if connection:
            try:
                cursor = connection.cursor()
                query = """
                INSERT INTO predictions (RevolvingUtilizationOfUnsecuredLines, age, `NumberOfTime30-59DaysPastDueNotWorse`, 
                DebtRatio, MonthlyIncome, NumberOfOpenCreditLinesAndLoans, NumberOfTimes90DaysLate, 
                NumberRealEstateLoansOrLines, `NumberOfTime60-89DaysPastDueNotWorse`, NumberOfDependents, prediction)
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                """
                cursor.execute(query, (*features[0], float(probability)))
                connection.commit()
                print("Data successfully inserted into AWS RDS MySQL database")
            except Error as e:
                print(f"Error inserting data into AWS RDS MySQL: {e}")
            finally:
                if connection.is_connected():
                    cursor.close()
                    connection.close()
        else:
            print("Failed to connect to the AWS RDS MySQL database")
        
        return jsonify(result)

    except Exception as e:
        print(f"An error occurred: {str(e)}")
        return jsonify({"error": "An internal server error occurred"}), 500

if __name__ == '__main__':
    app.run(debug=True)